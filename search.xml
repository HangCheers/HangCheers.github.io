<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[plotting]]></title>
    <url>%2F2019%2F01%2F13%2Fplotting%2F</url>
    <content type="text"><![CDATA[Hello, 2019年的第一篇博客。依旧是介绍一下我最近使用的几个很好用的工具。 百度开源的pyecharts。 之前「机器之心」认识的小伙伴weng jj推荐给我的。引用pyecharts官网文档的介绍，pyecharts相当于python版本的Echarts，是百度开源的一个数据可视化JS库。可以画饼状图、玫瑰图、折线图等多种类型的图。 下面举一个我做的一个很简单的例子。数据来源是kaggle上分析法国地区不平等的情况，经过了数据清理之后（此处省略，因为很简单0-o），我们得到了表格。此时我们想用表中的数据给可视化出来，参考pyechart文档，我们可以得到下面的图。 在全法国人均总工资最高的前十个地区，不同性别所拿到的工资的差异。 在全法国不同工作种类之间的工资差异。 从柱状图和上面的玫瑰图，我们就可以很轻而易举的看到差距啦（😁），而且pyecharts画出来的📈，比python带的matplotlib工具包画出的图表，视觉效果要好很多。]]></content>
      <categories>
        <category>磨刀不误砍柴工</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LaTex Installation on OSX]]></title>
    <url>%2F2018%2F12%2F19%2Flatex-installation-on-OSX%2F</url>
    <content type="text"><![CDATA[Latex在论文写作中用的比较多，比word好用不少。Latex最大的优势就是复杂公式的编辑与排版非常漂亮。今天记录一下在mac OSX环境下如何舒服的敲Latex。解决方案：Sublime Text + MacTex + Skim MacTeX是TeXLive的Mac版，在http://www.tug.org/mactex/中下载MacTex.pkg。 安装完成后，会出现如下界面。 Sublime Text 是编辑器，首先按「command + shift + P」来打开命令行，然后输入命令「Install Package」,按下Enter回车键。在输入完成后，再输入“LaTex Tools”并安装。我们可以在安装package的过程中，可以打开console。Console一般在ST3的底部，用来查看安装的进程。 . Skim是在OSX下面比较轻便的一个PDF阅读器。安装完阅读阅读器，需要「Sync」一下Sublime Text和Skim，如果下载的是Sublime Text3就选Sublime Text，如果是Sublime Text2就选择Sublime Text2。 PS，LaTex Templates上提供了很多简历模版，可以借鉴参考。]]></content>
      <categories>
        <category>磨刀不误砍柴工</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FAIR视觉论文集锦]]></title>
    <url>%2F2018%2F12%2F16%2Floss%2F</url>
    <content type="text"><![CDATA[FAIR在目标检测、实力分割等领域都做了创新。本篇博客从R-CNN到FPN到RetinaNet到Mask-RCNN做了一点归纳总结。 Faster-RCNN首先来提Faster-RCNN 网络结构，是因为Mask-RCNN是在其基础上改进网络结果「更具体点并列加一个mask branch」而得到的来实现segmentation。Faster-RCNN在object detection中相当于baseline system，也是benchmark。主要包括了对目标物体的分类（classification），以及用候选框（bounding box）来对图片中的位置进行定位。在此之前也已有了Fast-RCNN之类的目标检测算法了。文章「Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks」的创新在于解决了Region Proposal生成开销问题。当生成的候选框过多时，processing speed会受到影响，从而没法很好的实现real-time object detection。 we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals 在Faster-RCNN中使用RPN来进行候选框的确定，即「Region proposal Network找出物体可能存在的所有位置」，在这一个过程中找全，没有漏检很重要，不然后面的分类也没法分了。即Recall的值要高，「Recall=正确识别出来的object/数据库里含有的object，当recall=100%时，表示没有漏检」。RPN网络是一种全连接网络（FCN在下文有提到哈哈） RPN预测了object bounds and objectness scores at each position，这给Fast-RCNN起到类似指哪打哪的作用了。此外，这里也是文章的另一个创新点，通过「sharing the convolutional features」实现了RPN和Fast-RCNN融合到一个网络中去了。在这里我们来理解一下「sharing」，RPN从feature map 上选择出了一系列的bounding box，然后Fast-RCNN再次利用了feature map，并用ROI pooling（主要包括三步：1. 把 region proposal 分为n等分，n=the dimension of the output 2. 找到每个section最大的值 3.把每个最大的提取出来作为output buffer）来对每个candidate box进行classification 和 bounding box regression，也在一定程度上节省了计算开销，加速了训练过程。 using the recently popular terminology of neural networks with “attention” mechanisms, the RPN component tells the unified network where to look Feature Pyramid Network背景：ROI映射到某个feature map是将底层的坐标直接除以stride，显然对于小目标（size比较小）物体来说，到后面的卷积池化时，实际的语义信息就丢失了很多了。在CNN中，我们需要考虑不同种类的invariance来做识别，scale invariance很难被CNN考虑到。一般通常的做法有两种Image Pyramid和Feature Pyramid。其中Feature Pyramid的代表有SPPNet和FPN。 FPN结构：FPN是基于特征提取的网络，可以是ResNet也可以是DenseNet。在Mask-RCNN中就将ResNet和FPN相结合，作为base-network。常见的命名方式：主干网络-层数-FPN，如ResNet-101-FPN。在深度学习框架下，选取一个预训练模型就可以实现FPN。FPN设计的金字塔结构包括了bottom-up &amp; top-down &amp; lateral connections三种结构。bottom-up是主干CNN沿前向传输（feed-foward/inference)。top-down是上采样（upsampling) 。lateral connection通常使用 1x1的卷积，融合不同层的语义信息的同时降低维度，和upsampling叠加后得到不同分辨率的特征图，从而达到多尺度anchor的效果。 focal loss for dense object detection背景：目标检测中 根据有标签的数据划分 positive / negative training examples(其中通过 bounding box 的IOU来确定正负样本，IOU超过一定的阈值则为正样本)一般负样本会多于正样本.但是为了训练出来的模型不偏向于negative，需要保证样本数目的balance.Focal loss for dense object detection解决的就是 foreground-background即前景和背景的数据的imbalance。 创新：本文是通过「loss」改变为「focal loss」而不是「architecture」创新来speed/accuracy/complexity的trade-off，在这里指的一提的是主干网络「RetinaNet」。 Fully Convolutional NetworksFully Convolutional Networks for semantic segmentation 一开始说的： combines semantic information from a 「deep , coarse」 layer with appearance information from a 「shallow, fine」 layers 那为什么deep和coarse连在一起，shallow和fine来接在一起，不是越deep的层，越有表达力么？ 全连接网络和CNN之间的区别：经典的CNN是将卷积层产生的feature map使用全连接层映射为固定长度的特征向量，最后输出的是概率。FCN将全连接层都变化为卷积层，「E.X.: 将4096 变成1x1x4096」是针对语义分割训练的一个end-to-end, pixel的网络，最后输出的是heatmap热力图。 FCN网络结构创新点：FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map做上采样upsampling，使其恢复到输入图像的相同尺寸，从而对每一个像素都产生一个预测，同时保留原始输入图像的空间信息。但是这样得到的结果比较coarser, 一些细节不能恢复。因此，作者采用了skip architecture来优化上采样，即将不同池化层的结果进行上采样，然后结合这些结果来优化输出。「E.X 第五层的输出32倍放大反卷积到原图大小时比较粗糙，因此作者将第四层输出16倍放大，第3层输出8倍放大，可以从原论文中插图看到越低池化层，越精细」因此我们也就可以理解了上文的问题。 FCN在mask-RCNN中的应用：在the mask branch中，FCN被用在每个ROI中进行pixel-to-pixel的分割，这也是mask-RCNN超越了Faster-RCNN的地方。作者在文章里是这么说的： Our method, called Mask-RCNN，extends Faster-RCNN by adding a branch for predicting segmentation masks on each Region of Interest,in parallel with the existing branch for classification and bounding box regression. Mask-RCNNMask-RCNN论文地址 Mask-RCNN实现的任务要更「难」，因为不再是object detection 而是要达到instance segmentation，细化到区分类别中的不同实例。通俗点说，像素分类的话可以用不同的颜色来区别不同的实例，但是实例分割的时候即使是同一种类的物体，比如都是猫猫，也要区别出橘猫和加菲猫。像FCN中也可以用在实例分割的情景中，但它们的做法是，对每个像素进行multi-class categorization。作者提出的方法在实例分割中是更有优势的。 Instead, our method is based on parallel prediction of masks and class labels, which is simpler and more flexible.In contrast to the segmentation-first level of these methods, Mask R-CNN is based on an instance first strategy. 在上面介绍faster-RCNN时，已经提到了Mask-RCNN增加了分支，来预测物体对应的掩膜(object mask). 在阅读Mask-RCNN的时候，遇到一个问题「如何来理解pixel-to-pixel alignment 」 we propose a simple, quantiazation-free layer, called ROIAlign， that preserves exact spatial locations. faster-RCNN的ROI Pooling,ROI Pooling 存在两次量化（quantize）过程：第一次是将候选框的边界（通常是浮点数）量化成了整数点坐标，第二次是将量化后的边界区域平均分割成kxk个单元bin时，对每一个单元进行了量化。也可以理解为「粗暴的四舍五入」，使用了邻近插值法，从而选择离目标最近的点。但是这么做会带来一定的偏差，从而影响到分割的精确。也是文章中提到的misalignment。「放大后的图有马赛克，而缩小的图有失真」为了克服这一弊端，作者就取消了量化的过程了，使用双线性插值的方法。Mask-RCNN 用的方法是ROIAlign。 we use bilinear interpolation to compute the exact values of the input features at four regularly sampled locations in each ROI bin, and aggregate the result. 参考wiki双线性插值指的是对x，y方向各进行一次插值方法。在原图src(source)和目标图dst(destination)上进行图像的缩放。 充分利用src中四个真实的像素值来共同决定目标图中的一个像素值，缩放后的图像质量更高。假设src中四个点的坐标分别是（0，0）（0，1）（1，0）（1，1），公式如下所示： ROIAlign的做法带来的好处是： 1.it improves mask accuracy by relative 10% to 50%, showing bigger gains under stricter localization metrics. 2.we found it essential to decouple mask and class prediction: we predict the binary mask for each class independently.]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inception]]></title>
    <url>%2F2018%2F12%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Inception系列有四篇重要的paper，分别是：Going Deeper with Convolutions、Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shif、Rethinking the Inception Architecture for Computer Vision、Inception-v4在此，依次阅读并做笔记。 GoogleNetIntroduction &amp; MotivationGoing Deeper with Convolutions 首次提出了「Inception」模块作为网络构架，该网络构架也是后续作为classification和detection的base network的重要组成部分。 we introduce a new level of organization in the form of the “Inception module” and also in a more direct sense of increasednetwork depth. 网络的size主要从两方面进行考虑：depth - the number of levels - of the network 和 width - the number of units at each level。「加深网络depth」、「调节超参数」可以在recognition和object detection取得更好的效果。但是网络的size过大，会直接影响运行的性能。就像一个人过胖，会直接影响身体健康。当网络的size过大的时候，参数#paramters过多，消耗的计算资源就越多，此外，特别是在labeled examples很有限的情况下，更容易出现overfitting。一般是采用「dropout」或者「regularization」，并且「调整超参数」和「设置学习率」去防止训练过程中过拟合现象的出现。 For larger datasets such as Imagenet, deeper architectures are used to get better results and dropout is used to preventoverfitting …… Since in practice the computational budget is always finite, an efficient distribution of computing resources is preferred to an indiscriminate increase of size。 Inception module上面的方法挺好的，但也挺蛮烦的，所以作者试图结合「数据结构、网络结构」来考虑，如何设计一个创新性的architecture，来更好的利用计算资源以及稍微放心、大胆的设置参数一些? 首先，开个小分支，介绍一下「稀疏结构」的理论基础：Hebbian原理。 作者从neuroscience的角度得到了启发，提出了网络结构的创新：。该原理指出：各个神经元是组合效应，通过神经突触进行信息的传递，大脑皮层接收信息。此外，神经反射活动的持续与重复会导致神经元连接稳定性的持久提升，当两个神经元细胞A和B距离很近，并且A参与了对B重复、持续的兴奋，那么某些代谢变化会导致A将作为能使B兴奋的细胞。 neurons that fire together, wire together.将Fully Connected变为稀疏连接（sparse connection）的时候，可以在增加网络深度和宽度的同时减少参数个数，但是大部分的硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量变少，但计算所消耗的时间很难减少。GoogleNet希望做的就是既保证网络结构的稀疏性、又利用密集矩阵的高计算性能。 GoogleNet的核心是Inception module，而Inception相当于一个Convolutional building block，也是一个局部稀疏最优解的网络构架，然后我们在空间上做堆叠。下面我们结合论文的插图来仔细分析一下Inception module。图a是原始的Inception module，图b是借鉴了NIN（Network In Network）引入1x1的卷积操作，改进后的Inception module。 Our network will be built from convolutional building blocks.All we need is to find the optimal local construction and to repeat it spatially. 输入有四个分支，使用多个尺度（1x1或3x3或5x5）的卷积和池化进行特征提取「相当于将稀疏矩阵分解为密集矩阵」，每一尺度提取的特征是均匀分布的，但是经过「filter concatenation」这步操作后，输出的特征不再是均匀分布的，相关性强的特征会被加强，而相关性弱的特征会被弱化。这个相关性高的节点应该被连接在一起的结论，即是从神经网络的角度对Hebbian原理有效性的证明「filter concatenation」，这一步其实相当于沿着深度方向（或者说在depth这个维度）进行拼接， stack up the first volume to the second volume to make the dimensions match up …… Output a single output vector forming the input ofnext stage。 结合Udacity视频和code来加深一下对「filter concatenation」的理解 concatenated_tensor = tf.concat(3,[branch1, branch2, branch3, branch 4]) E.g:{General}：输入 28x28x192 volume ，并列经过 1x1卷积操作、3x3卷积操作、5x5卷积操作、max-pool，分别得到28x28x64、28x28x128、28x28x32、28x28x32 volume, 将并列的volume沿着深度方向进行拼接，输出 28x28x256 volume。 Feifei-Li的cs231n的课件里是描述CNN的：every layer of a ConvNet transforms one volume of activations to another through a differentiable function.We use three main types of layers to build ConvNet architectures:Convolutional Layer, Pooling Layer,and Fully-Connected Layer. Conv layer will compute the output of neurons that are connected to local regions in the input,each computing a dot product between their weights and a small region they are connected to the input volume.Pool layer will perform a downsampling operation along the spatial dimensions(width,height)FC layer will compute the class score,resulting in volume of size「1x1x#class」。 {Specific}：5x5的卷积操作得到了28x28x32的block。filter size =5x5x192，5 pixels width and height, 192 pixels depth（filter的深度需要和前一feature map的深度保持一致。） 设input volume width = W, the width of receptive field = F_w, zero padding on the border = P, stride = S那么output volume width = (W-F+2P)/S+1。同理也可以得到output volume height。此外, input volume depth = D1此外，被filter覆盖的图像区域称为receptive field，具体操作是：slide each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any position，即filter中的值和原始图像中receptive field中的像素值进行点积运算，产生activation map或feature map。图像一般都是局部相关的，第n+1层的每个神经元和第n层的receptive field中的神经元连接，而不需要和第n层的所有神经元连接，ConvNet具有local connectivity(局部连接) 的性质。当filter的receptive field越大，filter能够处理的原始输入内容的范围就越大。随着经过更多的卷积层，得到的激活映射也就具有更为复杂的特征。 设 number of filters = K, 也是output volume depth的值。当filter的数目越多，spatial dimensions就会保留的越好。CNN具有local connection和parameter sharing的特点。每个filter的权重的个数 = F_w x F_h x D1, 总的权重个数= F_w x F_h x D1 x K 我们再分析一下compution cost cs231n 指出： the largest bottleneck to be aware of when constructing the ConvNet is the memory bottle neck.we need to keep track of the intermediate volume size, the paramter size and the memory.Reference:cs231n 现在我们来分析一下，上面的图b相比图a的优势在哪里🧐。1x1的卷积是作为瓶颈层的作用，用很小的计算量可以增加一层特征变换和非线性变换。此外，一般涉及到改变通道数，都会使用1x1卷积操作，例如残差连接和Dense连接 the bottleneck is usually the smallest part of something我们来计算一下图a中5x5的卷积操作得到了28x28x32的block的时候，所需要的multiples的次数。以及图b中先使用1x1的卷积操作先得到28x28x16，再使用5x5的卷积操作得到了28x28x32的blcok的时候，所需要的multiples的次数。 1.图a (28x28x32) x (5x5x192) = 120million 「一个output volume所需要的乘积次数 x the number of output values」 2.图b （28x28x16) x (1x1x192) + (28x28x32) x (5x5x16) = 12.4 million 从上面👆两个对比可以知道1x1的卷积操作大大的减少了计算量。 GoogleNet’s architecture首先，为了有一个初步的印象，先截取了GoogleNet的一部分，我们可以注意到这里有一个「softmax」的分支，整个结构中有两个「softmax」，它相当于辅助分类器，结合code我们可以知道该操作是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中起到的是梯度前向传输的作用。论文里是这么交代的： By adding auxiliary classifiers connected to these intermediate layers, we would expect to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization. 其次，为了对GoogleNet的组成有一个概念，引用了论文中的表格：上面讨论时，已经说过GoogleNet是模块化的，堆叠了多个Inception Module，靠后的Inception Module能够抽取更高阶的抽象的特征。 Batch NormalizationInternal covariate shift“Internal”指的是神经网络的隐含层，”Covariate”指的是输入的权重参数化，“Internal Covariate Shift”指的是在训练的过程中，输入的概率分布不固定，网络的参数在不断的变化，神经网络的隐含层也要不断的去「适应」新的分布。这个现象会让模型更加难训练，我们也需要更加谨慎的初始化模型参数和学习率。因此作者引入了Normalization 来解决这个问题。 Normalization通过规范化的手段，将每层神经网络任意神经元这个输入值的分布“强行拉回”到均值为0，方差为1的分布中.常规的正则化公式为：$\hat{x}^{k}=\frac{x^{k}-E(x^{k})}{\sqrt{var(x^{k})}}$这么做的优点是可以加快收敛的速度，但是缺点是假如该层的各个特征互不相关，简单的正则化操作可能会改变该层的特征表达。为了确保神经网络里面可以进行恒等变换(identity transform)，我们需要对常规的正则化公式进行改变。由此我们也引入了Batch Normalization:$BN_{\gamma,\beta}$。 $y^{k}=\gamma^{k}\hat{x^{k}}$;$\beta^{k}$其中每一个activation都会引入两个超参数$\gamma,\beta$。这两个参数也是神经网络需要学习的参数，分别起到的是scale和shift的作用。相当于在原来正则化的基础上，再进行了一次线性变化。在mini-batch的训练过程中，BN是规范化了每一层的输入，$z=g(BN(W,u))$ 「g表示的非线性操作，例如：relu」，从而减少了Internal Covariate shift的干扰。 the inputs to each layer are affected by the parameters of all preceding layers - so that smallchanges to the network parameters amplify as the network becomes deeper …… Fixed distribution of inputs to asub-network would have a positive consequences for the layers outside the network, as well. 此外，BN的创新也在于applied to the sub-networks and layers, incorporate the normalization in the network architecture as well。 Batch Normalization不仅允许不那么谨慎的初始化，还允许使用更高的learning rate。 Rethinking the Inception Architecture for Computer vision因为计算开销、参数量限制了把Inception部署到移动端和一些场景中，在abstract里，作者指出了对网络构架进行改进的思路。 Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by factorized convolutions and aggressive regularization. 卷积核的因式分解Paper里探索了几张将较大的卷积核分解为较小的卷积核的设置方式。例如：5x5的卷积核替换为两个3x3的卷积核；3x3的卷积核替换为1x3和3x1的卷积核。这样具有相同的receptive field的同时可以大大的减小计算开销。 需要注意的是「nxn的卷积被替换为1xn和nx1的卷积」的这种空间上分解为非对称卷积的做法在前面几层layer的效果不是很好，更适用于中等规格大小的feature map，（m的范围从12到20）。此外我们还要思考🤔几个问题。1.用小卷积核替换大卷积核，是否会带来信息损失(loss of expressiveness)? 不会，只要多次叠加的小卷积核和开始的大卷积核具有相同的receptive field。2.如果我们的目标是对计算开销中的线性部分进行因式分解，那么为什么不直接在第一次保持线性激活（linear activation）？因为在实验中表明，非线性激活性能更好。 Label Smoothing Regularization因为大多数的数据集都存在错误的标签， 但是minimize the cost function on the wrong labels can be harmful。因此在Model Regularization中，可以通过在训练的过程中主动加入噪声作为penalty，这样的模型具有noise Robustness。Label Smoothing Regularization(LSR)是其中的一种regularization的方法。 Here we propose a mechanism to regularize the classifier layer by estimating the marginalized effect of label-dropout duringtraining. {举一个University of Waterloo的WAVE LAB的 ME 780中lecture 3：Regularization for deep models的例子来帮助理解：ground-truth: y1_label=[1,0,0,……，0]prediction: 经过softmax classifier得到的softmax output: y1_out=[0.87,0.001,0.04……,0.03]. } maximum likelihood learning with softmax classifier and hard targets may actually never converge, the softmax cannever predict a probability of exactly 0 or 1, so it will continue to learn larger and larger weights, making moreextreme predictions. 假设x为training example，$p(k|x)$为x属于「label k」的概率，$q(k|x)$为x属于「ground-truth label」的概率。为了方便起见，忽略了p和q在example x上的相关性。 目标函数：「最小化交叉熵」。因为交叉熵衡量的是两个分布（p和q）的相似性，最小化目标函数是为了让预测的label概率分布$p(k|x)$（即例如上面的softmax的输出）和ground-truth label的概率分布$q(k|x)$尽可能的接近。「最小化交叉熵」也等价为「最大化似然函数」。但是我们需要对这个目标函数进行了改进。因为在单类情况下，单一的交叉熵导致样本属于某个类别的概率非常大，模型太过与自信自己的判断。这样会导致过拟合，此外还会降低模型的适应能力。为了避免模型过于自信，引入了一个独立于样本分布的变量u(k)，这相当于在ground-truth distribution中加入了噪声，组成一个新的分布。在实验中，使用的是均匀分布(uniform distribution)代替了u(k) we propose a mechanism for encouraging the model to be less confident. While this may not be desired if the goal is to maximize the log-likelihood of training labels, it does regularize the model and makes it more adaptable …… we refer to thischange in ground-truth label distribution as label-smoothing regularization, or LSR. Resnetintroduction一般来说，模型的深度加深，学习能力增强，但是不能简单的增加网络的深度，否则会出现随着网络深度增加，training error和test error变高的现象。这也说明网络结构变复杂时，optimization变得更加困难。Kaiming He提出了深度残差学习（deep residual learning framework）,通过网络结构的创新来有效的解决了上述的梯度弥散现象(degradation)。 网络结构 从以下两点来分析网络结构的创新 shortcut connection残差的网络结构是前向神经网络+shortcut。从上图可以看出在已有的网络结构中增加了一个branch，起到的是恒等映射（identity mapping）的作用，这样保证了一个深度模型的training error最起码保证shallow counterpart模型的training error是一致的，错误率不会高于浅层。此外，这种做法既不会增加额外的参数也不会增加额外的计算量。 residual representations两种函数的表达效果是相同的，但是优化的难度是不同的。对残差进行拟合显然要更加容易。残差函数 $F(x):=H(x)-x$。引入残差后的映射对输出的变化更加敏感，如H(5)=5.1,F(5)=0.1, 输出从5.1变化到5.2，增加的幅度为2%，但是残差是从0.1变化到0.2，增加幅度为100%。残差的思想就是去除相同的主体部分，突出微小的变化。 计算公式$${y}=F({x},{W_i})+W_s{x}$$其中$F({x},{W_i})$和$x$是需要学习的残差映射，在计算的时候需要保证维数一致，考虑到在两个feature map 中进行逐元素相加（element-wise addition)。当维数不一致的时候，通过引入线性映射W_s来匹配维度 最终取得的效果是： these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. Inception-Resnet因为Residual connections在训练深度网络时，十分有优势，再加上inception网络的深度也比较深，所以作者尝试将两种方法结合起来。更确切的说是，将Inception中的filter concatenation中的一部分替换为residual connections的结构。结合了residual connection的inception模块如下所示： 但是引入residual connection后，网络太深，稳定性不好，因此再次做了修改。图中inception框可以用任意其他subnetwork替代，但是这次修改是在输出后引入了缩放系数(scale),再相加和激活。文章提出了两个版本：Inception-ResNet v1和Inception-ResNet v2，相比原来，加快训练的收敛速度。在图像识别，视频检测等领域都作为了base-network。 In the experimental section we demonstrate that it is not very difficult to train competitive very deep networks without utilizing residual connections. However the use of residual connections seems to improve the training speed greatly, which is alone a great argument for their use.]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>入门</tag>
      </tags>
  </entry>
</search>
