<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[FAIRè§†è§‰è®ºæ–‡é›†é”¦]]></title>
    <url>%2F2018%2F12%2F16%2Floss%2F</url>
    <content type="text"><![CDATA[FAIRåœ¨ç›®æ ‡æ£€æµ‹ã€å®žåŠ›åˆ†å‰²ç­‰é¢†åŸŸéƒ½åšäº†åˆ›æ–°ã€‚æœ¬ç¯‡åšå®¢ä»ŽR-CNNåˆ°FPNåˆ°RetinaNetåˆ°Mask-RCNNåšäº†ä¸€ç‚¹å½’çº³æ€»ç»“ã€‚ Faster-RCNNé¦–å…ˆæ¥æFaster-RCNN ç½‘ç»œç»“æž„ï¼Œæ˜¯å› ä¸ºMask-RCNNæ˜¯åœ¨å…¶åŸºç¡€ä¸Šæ”¹è¿›ç½‘ç»œç»“æžœã€Œæ›´å…·ä½“ç‚¹å¹¶åˆ—åŠ ä¸€ä¸ªmask branchã€è€Œå¾—åˆ°çš„æ¥å®žçŽ°segmentationã€‚Faster-RCNNåœ¨object detectionä¸­ç›¸å½“äºŽbaseline systemï¼Œä¹Ÿæ˜¯benchmarkã€‚ä¸»è¦åŒ…æ‹¬äº†å¯¹ç›®æ ‡ç‰©ä½“çš„åˆ†ç±»ï¼ˆclassificationï¼‰ï¼Œä»¥åŠç”¨å€™é€‰æ¡†ï¼ˆbounding boxï¼‰æ¥å¯¹å›¾ç‰‡ä¸­çš„ä½ç½®è¿›è¡Œå®šä½ã€‚åœ¨æ­¤ä¹‹å‰ä¹Ÿå·²æœ‰äº†Fast-RCNNä¹‹ç±»çš„ç›®æ ‡æ£€æµ‹ç®—æ³•äº†ã€‚æ–‡ç« ã€ŒFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networksã€çš„åˆ›æ–°åœ¨äºŽè§£å†³äº†Region Proposalç”Ÿæˆå¼€é”€é—®é¢˜ã€‚å½“ç”Ÿæˆçš„å€™é€‰æ¡†è¿‡å¤šæ—¶ï¼Œprocessing speedä¼šå—åˆ°å½±å“ï¼Œä»Žè€Œæ²¡æ³•å¾ˆå¥½çš„å®žçŽ°real-time object detectionã€‚ we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals åœ¨Faster-RCNNä¸­ä½¿ç”¨RPNæ¥è¿›è¡Œå€™é€‰æ¡†çš„ç¡®å®šï¼Œå³ã€ŒRegion proposal Networkæ‰¾å‡ºç‰©ä½“å¯èƒ½å­˜åœ¨çš„æ‰€æœ‰ä½ç½®ã€ï¼Œåœ¨è¿™ä¸€ä¸ªè¿‡ç¨‹ä¸­æ‰¾å…¨ï¼Œæ²¡æœ‰æ¼æ£€å¾ˆé‡è¦ï¼Œä¸ç„¶åŽé¢çš„åˆ†ç±»ä¹Ÿæ²¡æ³•åˆ†äº†ã€‚å³Recallçš„å€¼è¦é«˜ï¼Œã€ŒRecall=æ­£ç¡®è¯†åˆ«å‡ºæ¥çš„object/æ•°æ®åº“é‡Œå«æœ‰çš„objectï¼Œå½“recall=100%æ—¶ï¼Œè¡¨ç¤ºæ²¡æœ‰æ¼æ£€ã€ã€‚RPNç½‘ç»œæ˜¯ä¸€ç§å…¨è¿žæŽ¥ç½‘ç»œï¼ˆFCNåœ¨ä¸‹æ–‡æœ‰æåˆ°å“ˆå“ˆï¼‰ RPNé¢„æµ‹äº†object bounds and objectness scores at each positionï¼Œè¿™ç»™Fast-RCNNèµ·åˆ°ç±»ä¼¼æŒ‡å“ªæ‰“å“ªçš„ä½œç”¨äº†ã€‚æ­¤å¤–ï¼Œè¿™é‡Œä¹Ÿæ˜¯æ–‡ç« çš„å¦ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œé€šè¿‡ã€Œsharing the convolutional featuresã€å®žçŽ°äº†RPNå’ŒFast-RCNNèžåˆåˆ°ä¸€ä¸ªç½‘ç»œä¸­åŽ»äº†ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æ¥ç†è§£ä¸€ä¸‹ã€Œsharingã€ï¼ŒRPNä»Žfeature map ä¸Šé€‰æ‹©å‡ºäº†ä¸€ç³»åˆ—çš„bounding boxï¼Œç„¶åŽFast-RCNNå†æ¬¡åˆ©ç”¨äº†feature mapï¼Œå¹¶ç”¨ROI poolingï¼ˆä¸»è¦åŒ…æ‹¬ä¸‰æ­¥ï¼š1. æŠŠ region proposal åˆ†ä¸ºnç­‰åˆ†ï¼Œn=the dimension of the output 2. æ‰¾åˆ°æ¯ä¸ªsectionæœ€å¤§çš„å€¼ 3.æŠŠæ¯ä¸ªæœ€å¤§çš„æå–å‡ºæ¥ä½œä¸ºoutput bufferï¼‰æ¥å¯¹æ¯ä¸ªcandidate boxè¿›è¡Œclassification å’Œ bounding box regressionï¼Œä¹Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸ŠèŠ‚çœäº†è®¡ç®—å¼€é”€ï¼ŒåŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ã€‚ using the recently popular terminology of neural networks with â€œattentionâ€ mechanisms, the RPN component tells the unified network where to look Feature Pyramid NetworkèƒŒæ™¯ï¼šROIæ˜ å°„åˆ°æŸä¸ªfeature mapæ˜¯å°†åº•å±‚çš„åæ ‡ç›´æŽ¥é™¤ä»¥strideï¼Œæ˜¾ç„¶å¯¹äºŽå°ç›®æ ‡ï¼ˆsizeæ¯”è¾ƒå°ï¼‰ç‰©ä½“æ¥è¯´ï¼Œåˆ°åŽé¢çš„å·ç§¯æ± åŒ–æ—¶ï¼Œå®žé™…çš„è¯­ä¹‰ä¿¡æ¯å°±ä¸¢å¤±äº†å¾ˆå¤šäº†ã€‚åœ¨CNNä¸­ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ä¸åŒç§ç±»çš„invarianceæ¥åšè¯†åˆ«ï¼Œscale invarianceå¾ˆéš¾è¢«CNNè€ƒè™‘åˆ°ã€‚ä¸€èˆ¬é€šå¸¸çš„åšæ³•æœ‰ä¸¤ç§Image Pyramidå’ŒFeature Pyramidã€‚å…¶ä¸­Feature Pyramidçš„ä»£è¡¨æœ‰SPPNetå’ŒFPNã€‚ FPNç»“æž„ï¼šFPNæ˜¯åŸºäºŽç‰¹å¾æå–çš„ç½‘ç»œï¼Œå¯ä»¥æ˜¯ResNetä¹Ÿå¯ä»¥æ˜¯DenseNetã€‚åœ¨Mask-RCNNä¸­å°±å°†ResNetå’ŒFPNç›¸ç»“åˆï¼Œä½œä¸ºbase-networkã€‚å¸¸è§çš„å‘½åæ–¹å¼ï¼šä¸»å¹²ç½‘ç»œ-å±‚æ•°-FPNï¼Œå¦‚ResNet-101-FPNã€‚åœ¨æ·±åº¦å­¦ä¹ æ¡†æž¶ä¸‹ï¼Œé€‰å–ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡åž‹å°±å¯ä»¥å®žçŽ°FPNã€‚FPNè®¾è®¡çš„é‡‘å­—å¡”ç»“æž„åŒ…æ‹¬äº†bottom-up &amp; top-down &amp; lateral connectionsä¸‰ç§ç»“æž„ã€‚bottom-upæ˜¯ä¸»å¹²CNNæ²¿å‰å‘ä¼ è¾“ï¼ˆfeed-foward/inference)ã€‚top-downæ˜¯ä¸Šé‡‡æ ·ï¼ˆupsampling) ã€‚lateral connectioné€šå¸¸ä½¿ç”¨ 1x1çš„å·ç§¯ï¼Œèžåˆä¸åŒå±‚çš„è¯­ä¹‰ä¿¡æ¯çš„åŒæ—¶é™ä½Žç»´åº¦ï¼Œå’Œupsamplingå åŠ åŽå¾—åˆ°ä¸åŒåˆ†è¾¨çŽ‡çš„ç‰¹å¾å›¾ï¼Œä»Žè€Œè¾¾åˆ°å¤šå°ºåº¦anchorçš„æ•ˆæžœã€‚ focal loss for dense object detectionèƒŒæ™¯ï¼šç›®æ ‡æ£€æµ‹ä¸­ æ ¹æ®æœ‰æ ‡ç­¾çš„æ•°æ®åˆ’åˆ† positive / negative training examples(å…¶ä¸­é€šè¿‡ bounding box çš„IOUæ¥ç¡®å®šæ­£è´Ÿæ ·æœ¬ï¼ŒIOUè¶…è¿‡ä¸€å®šçš„é˜ˆå€¼åˆ™ä¸ºæ­£æ ·æœ¬)ä¸€èˆ¬è´Ÿæ ·æœ¬ä¼šå¤šäºŽæ­£æ ·æœ¬.ä½†æ˜¯ä¸ºäº†è®­ç»ƒå‡ºæ¥çš„æ¨¡åž‹ä¸åå‘äºŽnegativeï¼Œéœ€è¦ä¿è¯æ ·æœ¬æ•°ç›®çš„balance.Focal loss for dense object detectionè§£å†³çš„å°±æ˜¯ foreground-backgroundå³å‰æ™¯å’ŒèƒŒæ™¯çš„æ•°æ®çš„imbalanceã€‚ åˆ›æ–°ï¼šæœ¬æ–‡æ˜¯é€šè¿‡ã€Œlossã€æ”¹å˜ä¸ºã€Œfocal lossã€è€Œä¸æ˜¯ã€Œarchitectureã€åˆ›æ–°æ¥speed/accuracy/complexityçš„trade-offï¼Œåœ¨è¿™é‡ŒæŒ‡çš„ä¸€æçš„æ˜¯ä¸»å¹²ç½‘ç»œã€ŒRetinaNetã€ã€‚ Fully Convolutional NetworksFully Convolutional Networks for semantic segmentation ä¸€å¼€å§‹è¯´çš„ï¼š combines semantic information from a ã€Œdeep , coarseã€ layer with appearance information from a ã€Œshallow, fineã€ layers é‚£ä¸ºä»€ä¹ˆdeepå’Œcoarseè¿žåœ¨ä¸€èµ·ï¼Œshallowå’Œfineæ¥æŽ¥åœ¨ä¸€èµ·ï¼Œä¸æ˜¯è¶Šdeepçš„å±‚ï¼Œè¶Šæœ‰è¡¨è¾¾åŠ›ä¹ˆï¼Ÿ å…¨è¿žæŽ¥ç½‘ç»œå’ŒCNNä¹‹é—´çš„åŒºåˆ«ï¼šç»å…¸çš„CNNæ˜¯å°†å·ç§¯å±‚äº§ç”Ÿçš„feature mapä½¿ç”¨å…¨è¿žæŽ¥å±‚æ˜ å°„ä¸ºå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œæœ€åŽè¾“å‡ºçš„æ˜¯æ¦‚çŽ‡ã€‚FCNå°†å…¨è¿žæŽ¥å±‚éƒ½å˜åŒ–ä¸ºå·ç§¯å±‚ï¼Œã€ŒE.X.: å°†4096 å˜æˆ1x1x4096ã€æ˜¯é’ˆå¯¹è¯­ä¹‰åˆ†å‰²è®­ç»ƒçš„ä¸€ä¸ªend-to-end, pixelçš„ç½‘ç»œï¼Œæœ€åŽè¾“å‡ºçš„æ˜¯heatmapçƒ­åŠ›å›¾ã€‚ FCNç½‘ç»œç»“æž„åˆ›æ–°ç‚¹ï¼šFCNå¯ä»¥æŽ¥å—ä»»æ„å°ºå¯¸çš„è¾“å…¥å›¾åƒï¼Œé‡‡ç”¨åå·ç§¯å±‚å¯¹æœ€åŽä¸€ä¸ªå·ç§¯å±‚çš„feature mapåšä¸Šé‡‡æ ·upsamplingï¼Œä½¿å…¶æ¢å¤åˆ°è¾“å…¥å›¾åƒçš„ç›¸åŒå°ºå¯¸ï¼Œä»Žè€Œå¯¹æ¯ä¸€ä¸ªåƒç´ éƒ½äº§ç”Ÿä¸€ä¸ªé¢„æµ‹ï¼ŒåŒæ—¶ä¿ç•™åŽŸå§‹è¾“å…¥å›¾åƒçš„ç©ºé—´ä¿¡æ¯ã€‚ä½†æ˜¯è¿™æ ·å¾—åˆ°çš„ç»“æžœæ¯”è¾ƒcoarser, ä¸€äº›ç»†èŠ‚ä¸èƒ½æ¢å¤ã€‚å› æ­¤ï¼Œä½œè€…é‡‡ç”¨äº†skip architectureæ¥ä¼˜åŒ–ä¸Šé‡‡æ ·ï¼Œå³å°†ä¸åŒæ± åŒ–å±‚çš„ç»“æžœè¿›è¡Œä¸Šé‡‡æ ·ï¼Œç„¶åŽç»“åˆè¿™äº›ç»“æžœæ¥ä¼˜åŒ–è¾“å‡ºã€‚ã€ŒE.X ç¬¬äº”å±‚çš„è¾“å‡º32å€æ”¾å¤§åå·ç§¯åˆ°åŽŸå›¾å¤§å°æ—¶æ¯”è¾ƒç²—ç³™ï¼Œå› æ­¤ä½œè€…å°†ç¬¬å››å±‚è¾“å‡º16å€æ”¾å¤§ï¼Œç¬¬3å±‚è¾“å‡º8å€æ”¾å¤§ï¼Œå¯ä»¥ä»ŽåŽŸè®ºæ–‡ä¸­æ’å›¾çœ‹åˆ°è¶Šä½Žæ± åŒ–å±‚ï¼Œè¶Šç²¾ç»†ã€å› æ­¤æˆ‘ä»¬ä¹Ÿå°±å¯ä»¥ç†è§£äº†ä¸Šæ–‡çš„é—®é¢˜ã€‚ FCNåœ¨mask-RCNNä¸­çš„åº”ç”¨ï¼šåœ¨the mask branchä¸­ï¼ŒFCNè¢«ç”¨åœ¨æ¯ä¸ªROIä¸­è¿›è¡Œpixel-to-pixelçš„åˆ†å‰²ï¼Œè¿™ä¹Ÿæ˜¯mask-RCNNè¶…è¶Šäº†Faster-RCNNçš„åœ°æ–¹ã€‚ä½œè€…åœ¨æ–‡ç« é‡Œæ˜¯è¿™ä¹ˆè¯´çš„ï¼š Our method, called Mask-RCNNï¼Œextends Faster-RCNN by adding a branch for predicting segmentation masks on each Region of Interest,in parallel with the existing branch for classification and bounding box regression. Mask-RCNNMask-RCNNè®ºæ–‡åœ°å€ Mask-RCNNå®žçŽ°çš„ä»»åŠ¡è¦æ›´ã€Œéš¾ã€ï¼Œå› ä¸ºä¸å†æ˜¯object detection è€Œæ˜¯è¦è¾¾åˆ°instance segmentationï¼Œç»†åŒ–åˆ°åŒºåˆ†ç±»åˆ«ä¸­çš„ä¸åŒå®žä¾‹ã€‚é€šä¿—ç‚¹è¯´ï¼Œåƒç´ åˆ†ç±»çš„è¯å¯ä»¥ç”¨ä¸åŒçš„é¢œè‰²æ¥åŒºåˆ«ä¸åŒçš„å®žä¾‹ï¼Œä½†æ˜¯å®žä¾‹åˆ†å‰²çš„æ—¶å€™å³ä½¿æ˜¯åŒä¸€ç§ç±»çš„ç‰©ä½“ï¼Œæ¯”å¦‚éƒ½æ˜¯çŒ«çŒ«ï¼Œä¹Ÿè¦åŒºåˆ«å‡ºæ©˜çŒ«å’ŒåŠ è²çŒ«ã€‚åƒFCNä¸­ä¹Ÿå¯ä»¥ç”¨åœ¨å®žä¾‹åˆ†å‰²çš„æƒ…æ™¯ä¸­ï¼Œä½†å®ƒä»¬çš„åšæ³•æ˜¯ï¼Œå¯¹æ¯ä¸ªåƒç´ è¿›è¡Œmulti-class categorizationã€‚ä½œè€…æå‡ºçš„æ–¹æ³•åœ¨å®žä¾‹åˆ†å‰²ä¸­æ˜¯æ›´æœ‰ä¼˜åŠ¿çš„ã€‚ Instead, our method is based on parallel prediction of masks and class labels, which is simpler and more flexible.In contrast to the segmentation-first level of these methods, Mask R-CNN is based on an instance first strategy. åœ¨ä¸Šé¢ä»‹ç»faster-RCNNæ—¶ï¼Œå·²ç»æåˆ°äº†Mask-RCNNå¢žåŠ äº†åˆ†æ”¯ï¼Œæ¥é¢„æµ‹ç‰©ä½“å¯¹åº”çš„æŽ©è†œ(object mask). åœ¨é˜…è¯»Mask-RCNNçš„æ—¶å€™ï¼Œé‡åˆ°ä¸€ä¸ªé—®é¢˜ã€Œå¦‚ä½•æ¥ç†è§£pixel-to-pixel alignment ã€ we propose a simple, quantiazation-free layer, called ROIAlignï¼Œ that preserves exact spatial locations. faster-RCNNçš„ROI Pooling,ROI Pooling å­˜åœ¨ä¸¤æ¬¡é‡åŒ–ï¼ˆquantizeï¼‰è¿‡ç¨‹ï¼šç¬¬ä¸€æ¬¡æ˜¯å°†å€™é€‰æ¡†çš„è¾¹ç•Œï¼ˆé€šå¸¸æ˜¯æµ®ç‚¹æ•°ï¼‰é‡åŒ–æˆäº†æ•´æ•°ç‚¹åæ ‡ï¼Œç¬¬äºŒæ¬¡æ˜¯å°†é‡åŒ–åŽçš„è¾¹ç•ŒåŒºåŸŸå¹³å‡åˆ†å‰²æˆkxkä¸ªå•å…ƒbinæ—¶ï¼Œå¯¹æ¯ä¸€ä¸ªå•å…ƒè¿›è¡Œäº†é‡åŒ–ã€‚ä¹Ÿå¯ä»¥ç†è§£ä¸ºã€Œç²—æš´çš„å››èˆäº”å…¥ã€ï¼Œä½¿ç”¨äº†é‚»è¿‘æ’å€¼æ³•ï¼Œä»Žè€Œé€‰æ‹©ç¦»ç›®æ ‡æœ€è¿‘çš„ç‚¹ã€‚ä½†æ˜¯è¿™ä¹ˆåšä¼šå¸¦æ¥ä¸€å®šçš„åå·®ï¼Œä»Žè€Œå½±å“åˆ°åˆ†å‰²çš„ç²¾ç¡®ã€‚ä¹Ÿæ˜¯æ–‡ç« ä¸­æåˆ°çš„misalignmentã€‚ã€Œæ”¾å¤§åŽçš„å›¾æœ‰é©¬èµ›å…‹ï¼Œè€Œç¼©å°çš„å›¾æœ‰å¤±çœŸã€ä¸ºäº†å…‹æœè¿™ä¸€å¼Šç«¯ï¼Œä½œè€…å°±å–æ¶ˆäº†é‡åŒ–çš„è¿‡ç¨‹äº†ï¼Œä½¿ç”¨åŒçº¿æ€§æ’å€¼çš„æ–¹æ³•ã€‚Mask-RCNN ç”¨çš„æ–¹æ³•æ˜¯ROIAlignã€‚ we use bilinear interpolation to compute the exact values of the input features at four regularly sampled locations in each ROI bin, and aggregate the result. å‚è€ƒwikiåŒçº¿æ€§æ’å€¼æŒ‡çš„æ˜¯å¯¹xï¼Œyæ–¹å‘å„è¿›è¡Œä¸€æ¬¡æ’å€¼æ–¹æ³•ã€‚åœ¨åŽŸå›¾src(source)å’Œç›®æ ‡å›¾dst(destination)ä¸Šè¿›è¡Œå›¾åƒçš„ç¼©æ”¾ã€‚ å……åˆ†åˆ©ç”¨srcä¸­å››ä¸ªçœŸå®žçš„åƒç´ å€¼æ¥å…±åŒå†³å®šç›®æ ‡å›¾ä¸­çš„ä¸€ä¸ªåƒç´ å€¼ï¼Œç¼©æ”¾åŽçš„å›¾åƒè´¨é‡æ›´é«˜ã€‚å‡è®¾srcä¸­å››ä¸ªç‚¹çš„åæ ‡åˆ†åˆ«æ˜¯ï¼ˆ0ï¼Œ0ï¼‰ï¼ˆ0ï¼Œ1ï¼‰ï¼ˆ1ï¼Œ0ï¼‰ï¼ˆ1ï¼Œ1ï¼‰ï¼Œå…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š ROIAlignçš„åšæ³•å¸¦æ¥çš„å¥½å¤„æ˜¯ï¼š 1.it improves mask accuracy by relative 10% to 50%, showing bigger gains under stricter localization metrics. 2.we found it essential to decouple mask and class prediction: we predict the binary mask for each class independently.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>å…¥é—¨</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inception]]></title>
    <url>%2F2018%2F12%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Inceptionç³»åˆ—æœ‰å››ç¯‡é‡è¦çš„paperï¼Œåˆ†åˆ«æ˜¯ï¼šGoing Deeper with Convolutionsã€Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shifã€Rethinking the Inception Architecture for Computer Visionã€Inception-v4åœ¨æ­¤ï¼Œä¾æ¬¡é˜…è¯»å¹¶åšç¬”è®°ã€‚ GoogleNetIntroduction &amp; MotivationGoing Deeper with Convolutions é¦–æ¬¡æå‡ºäº†ã€ŒInceptionã€æ¨¡å—ä½œä¸ºç½‘ç»œæž„æž¶ï¼Œè¯¥ç½‘ç»œæž„æž¶ä¹Ÿæ˜¯åŽç»­ä½œä¸ºclassificationå’Œdetectionçš„base networkçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ we introduce a new level of organization in the form of the â€œInception moduleâ€ and also in a more direct sense of increasednetwork depth. ç½‘ç»œçš„sizeä¸»è¦ä»Žä¸¤æ–¹é¢è¿›è¡Œè€ƒè™‘ï¼šdepth - the number of levels - of the network å’Œ width - the number of units at each levelã€‚ã€ŒåŠ æ·±ç½‘ç»œdepthã€ã€ã€Œè°ƒèŠ‚è¶…å‚æ•°ã€å¯ä»¥åœ¨recognitionå’Œobject detectionå–å¾—æ›´å¥½çš„æ•ˆæžœã€‚ä½†æ˜¯ç½‘ç»œçš„sizeè¿‡å¤§ï¼Œä¼šç›´æŽ¥å½±å“è¿è¡Œçš„æ€§èƒ½ã€‚å°±åƒä¸€ä¸ªäººè¿‡èƒ–ï¼Œä¼šç›´æŽ¥å½±å“èº«ä½“å¥åº·ã€‚å½“ç½‘ç»œçš„sizeè¿‡å¤§çš„æ—¶å€™ï¼Œå‚æ•°#paramtersè¿‡å¤šï¼Œæ¶ˆè€—çš„è®¡ç®—èµ„æºå°±è¶Šå¤šï¼Œæ­¤å¤–ï¼Œç‰¹åˆ«æ˜¯åœ¨labeled exampleså¾ˆæœ‰é™çš„æƒ…å†µä¸‹ï¼Œæ›´å®¹æ˜“å‡ºçŽ°overfittingã€‚ä¸€èˆ¬æ˜¯é‡‡ç”¨ã€Œdropoutã€æˆ–è€…ã€Œregularizationã€ï¼Œå¹¶ä¸”ã€Œè°ƒæ•´è¶…å‚æ•°ã€å’Œã€Œè®¾ç½®å­¦ä¹ çŽ‡ã€åŽ»é˜²æ­¢è®­ç»ƒè¿‡ç¨‹ä¸­è¿‡æ‹ŸåˆçŽ°è±¡çš„å‡ºçŽ°ã€‚ For larger datasets such as Imagenet, deeper architectures are used to get better results and dropout is used to preventoverfitting â€¦â€¦ Since in practice the computational budget is always finite, an efficient distribution of computing resources is preferred to an indiscriminate increase of sizeã€‚ Inception moduleä¸Šé¢çš„æ–¹æ³•æŒºå¥½çš„ï¼Œä½†ä¹ŸæŒºè›®çƒ¦çš„ï¼Œæ‰€ä»¥ä½œè€…è¯•å›¾ç»“åˆã€Œæ•°æ®ç»“æž„ã€ç½‘ç»œç»“æž„ã€æ¥è€ƒè™‘ï¼Œå¦‚ä½•è®¾è®¡ä¸€ä¸ªåˆ›æ–°æ€§çš„architectureï¼Œæ¥æ›´å¥½çš„åˆ©ç”¨è®¡ç®—èµ„æºä»¥åŠç¨å¾®æ”¾å¿ƒã€å¤§èƒ†çš„è®¾ç½®å‚æ•°ä¸€äº›? é¦–å…ˆï¼Œå¼€ä¸ªå°åˆ†æ”¯ï¼Œä»‹ç»ä¸€ä¸‹ã€Œç¨€ç–ç»“æž„ã€çš„ç†è®ºåŸºç¡€ï¼šHebbianåŽŸç†ã€‚ ä½œè€…ä»Žneuroscienceçš„è§’åº¦å¾—åˆ°äº†å¯å‘ï¼Œæå‡ºäº†ç½‘ç»œç»“æž„çš„åˆ›æ–°ï¼šã€‚è¯¥åŽŸç†æŒ‡å‡ºï¼šå„ä¸ªç¥žç»å…ƒæ˜¯ç»„åˆæ•ˆåº”ï¼Œé€šè¿‡ç¥žç»çªè§¦è¿›è¡Œä¿¡æ¯çš„ä¼ é€’ï¼Œå¤§è„‘çš®å±‚æŽ¥æ”¶ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç¥žç»åå°„æ´»åŠ¨çš„æŒç»­ä¸Žé‡å¤ä¼šå¯¼è‡´ç¥žç»å…ƒè¿žæŽ¥ç¨³å®šæ€§çš„æŒä¹…æå‡ï¼Œå½“ä¸¤ä¸ªç¥žç»å…ƒç»†èƒžAå’ŒBè·ç¦»å¾ˆè¿‘ï¼Œå¹¶ä¸”Aå‚ä¸Žäº†å¯¹Bé‡å¤ã€æŒç»­çš„å…´å¥‹ï¼Œé‚£ä¹ˆæŸäº›ä»£è°¢å˜åŒ–ä¼šå¯¼è‡´Aå°†ä½œä¸ºèƒ½ä½¿Bå…´å¥‹çš„ç»†èƒžã€‚ neurons that fire together, wire together.å°†Fully Connectedå˜ä¸ºç¨€ç–è¿žæŽ¥ï¼ˆsparse connectionï¼‰çš„æ—¶å€™ï¼Œå¯ä»¥åœ¨å¢žåŠ ç½‘ç»œæ·±åº¦å’Œå®½åº¦çš„åŒæ—¶å‡å°‘å‚æ•°ä¸ªæ•°ï¼Œä½†æ˜¯å¤§éƒ¨åˆ†çš„ç¡¬ä»¶æ˜¯é’ˆå¯¹å¯†é›†çŸ©é˜µè®¡ç®—ä¼˜åŒ–çš„ï¼Œç¨€ç–çŸ©é˜µè™½ç„¶æ•°æ®é‡å˜å°‘ï¼Œä½†è®¡ç®—æ‰€æ¶ˆè€—çš„æ—¶é—´å¾ˆéš¾å‡å°‘ã€‚GoogleNetå¸Œæœ›åšçš„å°±æ˜¯æ—¢ä¿è¯ç½‘ç»œç»“æž„çš„ç¨€ç–æ€§ã€åˆåˆ©ç”¨å¯†é›†çŸ©é˜µçš„é«˜è®¡ç®—æ€§èƒ½ã€‚ GoogleNetçš„æ ¸å¿ƒæ˜¯Inception moduleï¼Œè€ŒInceptionç›¸å½“äºŽä¸€ä¸ªConvolutional building blockï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå±€éƒ¨ç¨€ç–æœ€ä¼˜è§£çš„ç½‘ç»œæž„æž¶ï¼Œç„¶åŽæˆ‘ä»¬åœ¨ç©ºé—´ä¸Šåšå †å ã€‚ä¸‹é¢æˆ‘ä»¬ç»“åˆè®ºæ–‡çš„æ’å›¾æ¥ä»”ç»†åˆ†æžä¸€ä¸‹Inception moduleã€‚å›¾aæ˜¯åŽŸå§‹çš„Inception moduleï¼Œå›¾bæ˜¯å€Ÿé‰´äº†NINï¼ˆNetwork In Networkï¼‰å¼•å…¥1x1çš„å·ç§¯æ“ä½œï¼Œæ”¹è¿›åŽçš„Inception moduleã€‚ Our network will be built from convolutional building blocks.All we need is to find the optimal local construction and to repeat it spatially. è¾“å…¥æœ‰å››ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šä¸ªå°ºåº¦ï¼ˆ1x1æˆ–3x3æˆ–5x5ï¼‰çš„å·ç§¯å’Œæ± åŒ–è¿›è¡Œç‰¹å¾æå–ã€Œç›¸å½“äºŽå°†ç¨€ç–çŸ©é˜µåˆ†è§£ä¸ºå¯†é›†çŸ©é˜µã€ï¼Œæ¯ä¸€å°ºåº¦æå–çš„ç‰¹å¾æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œä½†æ˜¯ç»è¿‡ã€Œfilter concatenationã€è¿™æ­¥æ“ä½œåŽï¼Œè¾“å‡ºçš„ç‰¹å¾ä¸å†æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œç›¸å…³æ€§å¼ºçš„ç‰¹å¾ä¼šè¢«åŠ å¼ºï¼Œè€Œç›¸å…³æ€§å¼±çš„ç‰¹å¾ä¼šè¢«å¼±åŒ–ã€‚è¿™ä¸ªç›¸å…³æ€§é«˜çš„èŠ‚ç‚¹åº”è¯¥è¢«è¿žæŽ¥åœ¨ä¸€èµ·çš„ç»“è®ºï¼Œå³æ˜¯ä»Žç¥žç»ç½‘ç»œçš„è§’åº¦å¯¹HebbianåŽŸç†æœ‰æ•ˆæ€§çš„è¯æ˜Žã€Œfilter concatenationã€ï¼Œè¿™ä¸€æ­¥å…¶å®žç›¸å½“äºŽæ²¿ç€æ·±åº¦æ–¹å‘ï¼ˆæˆ–è€…è¯´åœ¨depthè¿™ä¸ªç»´åº¦ï¼‰è¿›è¡Œæ‹¼æŽ¥ï¼Œ stack up the first volume to the second volume to make the dimensions match up â€¦â€¦ Output a single output vector forming the input ofnext stageã€‚ ç»“åˆUdacityè§†é¢‘å’Œcodeæ¥åŠ æ·±ä¸€ä¸‹å¯¹ã€Œfilter concatenationã€çš„ç†è§£ concatenated_tensor = tf.concat(3,[branch1, branch2, branch3, branch 4]) E.g:{General}ï¼šè¾“å…¥ 28x28x192 volume ï¼Œå¹¶åˆ—ç»è¿‡ 1x1å·ç§¯æ“ä½œã€3x3å·ç§¯æ“ä½œã€5x5å·ç§¯æ“ä½œã€max-poolï¼Œåˆ†åˆ«å¾—åˆ°28x28x64ã€28x28x128ã€28x28x32ã€28x28x32 volume, å°†å¹¶åˆ—çš„volumeæ²¿ç€æ·±åº¦æ–¹å‘è¿›è¡Œæ‹¼æŽ¥ï¼Œè¾“å‡º 28x28x256 volumeã€‚ Feifei-Liçš„cs231nçš„è¯¾ä»¶é‡Œæ˜¯æè¿°CNNçš„ï¼ševery layer of a ConvNet transforms one volume of activations to another through a differentiable function.We use three main types of layers to build ConvNet architectures:Convolutional Layer, Pooling Layer,and Fully-Connected Layer. Conv layer will compute the output of neurons that are connected to local regions in the input,each computing a dot product between their weights and a small region they are connected to the input volume.Pool layer will perform a downsampling operation along the spatial dimensions(width,height)FC layer will compute the class score,resulting in volume of sizeã€Œ1x1x#classã€ã€‚ {Specific}ï¼š5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blockã€‚filter size =5x5x192ï¼Œ5 pixels width and height, 192 pixels depthï¼ˆfilterçš„æ·±åº¦éœ€è¦å’Œå‰ä¸€feature mapçš„æ·±åº¦ä¿æŒä¸€è‡´ã€‚ï¼‰ è®¾input volume width = W, the width of receptive field = F_w, zero padding on the border = P, stride = Sé‚£ä¹ˆoutput volume width = (W-F+2P)/S+1ã€‚åŒç†ä¹Ÿå¯ä»¥å¾—åˆ°output volume heightã€‚æ­¤å¤–, input volume depth = D1æ­¤å¤–ï¼Œè¢«filterè¦†ç›–çš„å›¾åƒåŒºåŸŸç§°ä¸ºreceptive fieldï¼Œå…·ä½“æ“ä½œæ˜¯ï¼šslide each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any positionï¼Œå³filterä¸­çš„å€¼å’ŒåŽŸå§‹å›¾åƒä¸­receptive fieldä¸­çš„åƒç´ å€¼è¿›è¡Œç‚¹ç§¯è¿ç®—ï¼Œäº§ç”Ÿactivation mapæˆ–feature mapã€‚å›¾åƒä¸€èˆ¬éƒ½æ˜¯å±€éƒ¨ç›¸å…³çš„ï¼Œç¬¬n+1å±‚çš„æ¯ä¸ªç¥žç»å…ƒå’Œç¬¬nå±‚çš„receptive fieldä¸­çš„ç¥žç»å…ƒè¿žæŽ¥ï¼Œè€Œä¸éœ€è¦å’Œç¬¬nå±‚çš„æ‰€æœ‰ç¥žç»å…ƒè¿žæŽ¥ï¼ŒConvNetå…·æœ‰local connectivity(å±€éƒ¨è¿žæŽ¥) çš„æ€§è´¨ã€‚å½“filterçš„receptive fieldè¶Šå¤§ï¼Œfilterèƒ½å¤Ÿå¤„ç†çš„åŽŸå§‹è¾“å…¥å†…å®¹çš„èŒƒå›´å°±è¶Šå¤§ã€‚éšç€ç»è¿‡æ›´å¤šçš„å·ç§¯å±‚ï¼Œå¾—åˆ°çš„æ¿€æ´»æ˜ å°„ä¹Ÿå°±å…·æœ‰æ›´ä¸ºå¤æ‚çš„ç‰¹å¾ã€‚ è®¾ number of filters = K, ä¹Ÿæ˜¯output volume depthçš„å€¼ã€‚å½“filterçš„æ•°ç›®è¶Šå¤šï¼Œspatial dimensionså°±ä¼šä¿ç•™çš„è¶Šå¥½ã€‚CNNå…·æœ‰local connectionå’Œparameter sharingçš„ç‰¹ç‚¹ã€‚æ¯ä¸ªfilterçš„æƒé‡çš„ä¸ªæ•° = F_w x F_h x D1, æ€»çš„æƒé‡ä¸ªæ•°= F_w x F_h x D1 x K æˆ‘ä»¬å†åˆ†æžä¸€ä¸‹compution cost cs231n æŒ‡å‡ºï¼š the largest bottleneck to be aware of when constructing the ConvNet is the memory bottle neck.we need to keep track of the intermediate volume size, the paramter size and the memory.Reference:cs231n çŽ°åœ¨æˆ‘ä»¬æ¥åˆ†æžä¸€ä¸‹ï¼Œä¸Šé¢çš„å›¾bç›¸æ¯”å›¾açš„ä¼˜åŠ¿åœ¨å“ªé‡ŒðŸ§ã€‚1x1çš„å·ç§¯æ˜¯ä½œä¸ºç“¶é¢ˆå±‚çš„ä½œç”¨ï¼Œç”¨å¾ˆå°çš„è®¡ç®—é‡å¯ä»¥å¢žåŠ ä¸€å±‚ç‰¹å¾å˜æ¢å’Œéžçº¿æ€§å˜æ¢ã€‚æ­¤å¤–ï¼Œä¸€èˆ¬æ¶‰åŠåˆ°æ”¹å˜é€šé“æ•°ï¼Œéƒ½ä¼šä½¿ç”¨1x1å·ç§¯æ“ä½œï¼Œä¾‹å¦‚æ®‹å·®è¿žæŽ¥å’ŒDenseè¿žæŽ¥ the bottleneck is usually the smallest part of somethingæˆ‘ä»¬æ¥è®¡ç®—ä¸€ä¸‹å›¾aä¸­5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blockçš„æ—¶å€™ï¼Œæ‰€éœ€è¦çš„multiplesçš„æ¬¡æ•°ã€‚ä»¥åŠå›¾bä¸­å…ˆä½¿ç”¨1x1çš„å·ç§¯æ“ä½œå…ˆå¾—åˆ°28x28x16ï¼Œå†ä½¿ç”¨5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blcokçš„æ—¶å€™ï¼Œæ‰€éœ€è¦çš„multiplesçš„æ¬¡æ•°ã€‚ 1.å›¾a (28x28x32) x (5x5x192) = 120million ã€Œä¸€ä¸ªoutput volumeæ‰€éœ€è¦çš„ä¹˜ç§¯æ¬¡æ•° x the number of output valuesã€ 2.å›¾b ï¼ˆ28x28x16) x (1x1x192) + (28x28x32) x (5x5x16) = 12.4 million ä»Žä¸Šé¢ðŸ‘†ä¸¤ä¸ªå¯¹æ¯”å¯ä»¥çŸ¥é“1x1çš„å·ç§¯æ“ä½œå¤§å¤§çš„å‡å°‘äº†è®¡ç®—é‡ã€‚ GoogleNetâ€™s architectureé¦–å…ˆï¼Œä¸ºäº†æœ‰ä¸€ä¸ªåˆæ­¥çš„å°è±¡ï¼Œå…ˆæˆªå–äº†GoogleNetçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªã€Œsoftmaxã€çš„åˆ†æ”¯ï¼Œæ•´ä¸ªç»“æž„ä¸­æœ‰ä¸¤ä¸ªã€Œsoftmaxã€ï¼Œå®ƒç›¸å½“äºŽè¾…åŠ©åˆ†ç±»å™¨ï¼Œç»“åˆcodeæˆ‘ä»¬å¯ä»¥çŸ¥é“è¯¥æ“ä½œæ˜¯å°†ä¸­é—´æŸä¸€å±‚çš„è¾“å‡ºç”¨ä½œåˆ†ç±»ï¼Œå¹¶æŒ‰ä¸€ä¸ªè¾ƒå°çš„æƒé‡ï¼ˆ0.3ï¼‰åŠ åˆ°æœ€ç»ˆåˆ†ç±»ç»“æžœä¸­èµ·åˆ°çš„æ˜¯æ¢¯åº¦å‰å‘ä¼ è¾“çš„ä½œç”¨ã€‚è®ºæ–‡é‡Œæ˜¯è¿™ä¹ˆäº¤ä»£çš„ï¼š By adding auxiliary classifiers connected to these intermediate layers, we would expect to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization. å…¶æ¬¡ï¼Œä¸ºäº†å¯¹GoogleNetçš„ç»„æˆæœ‰ä¸€ä¸ªæ¦‚å¿µï¼Œå¼•ç”¨äº†è®ºæ–‡ä¸­çš„è¡¨æ ¼ï¼šä¸Šé¢è®¨è®ºæ—¶ï¼Œå·²ç»è¯´è¿‡GoogleNetæ˜¯æ¨¡å—åŒ–çš„ï¼Œå †å äº†å¤šä¸ªInception Moduleï¼Œé åŽçš„Inception Moduleèƒ½å¤ŸæŠ½å–æ›´é«˜é˜¶çš„æŠ½è±¡çš„ç‰¹å¾ã€‚ Batch NormalizationInternal covariate shiftâ€œInternalâ€æŒ‡çš„æ˜¯ç¥žç»ç½‘ç»œçš„éšå«å±‚ï¼Œâ€Covariateâ€æŒ‡çš„æ˜¯è¾“å…¥çš„æƒé‡å‚æ•°åŒ–ï¼Œâ€œInternal Covariate Shiftâ€æŒ‡çš„æ˜¯åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥çš„æ¦‚çŽ‡åˆ†å¸ƒä¸å›ºå®šï¼Œç½‘ç»œçš„å‚æ•°åœ¨ä¸æ–­çš„å˜åŒ–ï¼Œç¥žç»ç½‘ç»œçš„éšå«å±‚ä¹Ÿè¦ä¸æ–­çš„åŽ»ã€Œé€‚åº”ã€æ–°çš„åˆ†å¸ƒã€‚è¿™ä¸ªçŽ°è±¡ä¼šè®©æ¨¡åž‹æ›´åŠ éš¾è®­ç»ƒï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦æ›´åŠ è°¨æ…Žçš„åˆå§‹åŒ–æ¨¡åž‹å‚æ•°å’Œå­¦ä¹ çŽ‡ã€‚å› æ­¤ä½œè€…å¼•å…¥äº†Normalization æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ Normalizationé€šè¿‡è§„èŒƒåŒ–çš„æ‰‹æ®µï¼Œå°†æ¯å±‚ç¥žç»ç½‘ç»œä»»æ„ç¥žç»å…ƒè¿™ä¸ªè¾“å…¥å€¼çš„åˆ†å¸ƒâ€œå¼ºè¡Œæ‹‰å›žâ€åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„åˆ†å¸ƒä¸­.å¸¸è§„çš„æ­£åˆ™åŒ–å…¬å¼ä¸ºï¼š$\hat{x}^{k}=\frac{x^{k}-E(x^{k})}{\sqrt{var(x^{k})}}$è¿™ä¹ˆåšçš„ä¼˜ç‚¹æ˜¯å¯ä»¥åŠ å¿«æ”¶æ•›çš„é€Ÿåº¦ï¼Œä½†æ˜¯ç¼ºç‚¹æ˜¯å‡å¦‚è¯¥å±‚çš„å„ä¸ªç‰¹å¾äº’ä¸ç›¸å…³ï¼Œç®€å•çš„æ­£åˆ™åŒ–æ“ä½œå¯èƒ½ä¼šæ”¹å˜è¯¥å±‚çš„ç‰¹å¾è¡¨è¾¾ã€‚ä¸ºäº†ç¡®ä¿ç¥žç»ç½‘ç»œé‡Œé¢å¯ä»¥è¿›è¡Œæ’ç­‰å˜æ¢(identity transform)ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å¸¸è§„çš„æ­£åˆ™åŒ–å…¬å¼è¿›è¡Œæ”¹å˜ã€‚ç”±æ­¤æˆ‘ä»¬ä¹Ÿå¼•å…¥äº†Batch Normalization:$BN_{\gamma,\beta}$ã€‚ $y^{k}=\gamma^{k}\hat{x^{k}}$;$\beta^{k}$å…¶ä¸­æ¯ä¸€ä¸ªactivationéƒ½ä¼šå¼•å…¥ä¸¤ä¸ªè¶…å‚æ•°$\gamma,\beta$ã€‚è¿™ä¸¤ä¸ªå‚æ•°ä¹Ÿæ˜¯ç¥žç»ç½‘ç»œéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œåˆ†åˆ«èµ·åˆ°çš„æ˜¯scaleå’Œshiftçš„ä½œç”¨ã€‚ç›¸å½“äºŽåœ¨åŽŸæ¥æ­£åˆ™åŒ–çš„åŸºç¡€ä¸Šï¼Œå†è¿›è¡Œäº†ä¸€æ¬¡çº¿æ€§å˜åŒ–ã€‚åœ¨mini-batchçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒBNæ˜¯è§„èŒƒåŒ–äº†æ¯ä¸€å±‚çš„è¾“å…¥ï¼Œ$z=g(BN(W,u))$ ã€Œgè¡¨ç¤ºçš„éžçº¿æ€§æ“ä½œï¼Œä¾‹å¦‚ï¼šreluã€ï¼Œä»Žè€Œå‡å°‘äº†Internal Covariate shiftçš„å¹²æ‰°ã€‚ the inputs to each layer are affected by the parameters of all preceding layers - so that smallchanges to the network parameters amplify as the network becomes deeper â€¦â€¦ Fixed distribution of inputs to asub-network would have a positive consequences for the layers outside the network, as well. æ­¤å¤–ï¼ŒBNçš„åˆ›æ–°ä¹Ÿåœ¨äºŽapplied to the sub-networks and layers, incorporate the normalization in the network architecture as wellã€‚ Batch Normalizationä¸ä»…å…è®¸ä¸é‚£ä¹ˆè°¨æ…Žçš„åˆå§‹åŒ–ï¼Œè¿˜å…è®¸ä½¿ç”¨æ›´é«˜çš„learning rateã€‚ Rethinking the Inception Architecture for Computer visionå› ä¸ºè®¡ç®—å¼€é”€ã€å‚æ•°é‡é™åˆ¶äº†æŠŠInceptionéƒ¨ç½²åˆ°ç§»åŠ¨ç«¯å’Œä¸€äº›åœºæ™¯ä¸­ï¼Œåœ¨abstracté‡Œï¼Œä½œè€…æŒ‡å‡ºäº†å¯¹ç½‘ç»œæž„æž¶è¿›è¡Œæ”¹è¿›çš„æ€è·¯ã€‚ Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by factorized convolutions and aggressive regularization. å·ç§¯æ ¸çš„å› å¼åˆ†è§£Paperé‡ŒæŽ¢ç´¢äº†å‡ å¼ å°†è¾ƒå¤§çš„å·ç§¯æ ¸åˆ†è§£ä¸ºè¾ƒå°çš„å·ç§¯æ ¸çš„è®¾ç½®æ–¹å¼ã€‚ä¾‹å¦‚ï¼š5x5çš„å·ç§¯æ ¸æ›¿æ¢ä¸ºä¸¤ä¸ª3x3çš„å·ç§¯æ ¸ï¼›3x3çš„å·ç§¯æ ¸æ›¿æ¢ä¸º1x3å’Œ3x1çš„å·ç§¯æ ¸ã€‚è¿™æ ·å…·æœ‰ç›¸åŒçš„receptive fieldçš„åŒæ—¶å¯ä»¥å¤§å¤§çš„å‡å°è®¡ç®—å¼€é”€ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ã€Œnxnçš„å·ç§¯è¢«æ›¿æ¢ä¸º1xnå’Œnx1çš„å·ç§¯ã€çš„è¿™ç§ç©ºé—´ä¸Šåˆ†è§£ä¸ºéžå¯¹ç§°å·ç§¯çš„åšæ³•åœ¨å‰é¢å‡ å±‚layerçš„æ•ˆæžœä¸æ˜¯å¾ˆå¥½ï¼Œæ›´é€‚ç”¨äºŽä¸­ç­‰è§„æ ¼å¤§å°çš„feature mapï¼Œï¼ˆmçš„èŒƒå›´ä»Ž12åˆ°20ï¼‰ã€‚æ­¤å¤–æˆ‘ä»¬è¿˜è¦æ€è€ƒðŸ¤”å‡ ä¸ªé—®é¢˜ã€‚1.ç”¨å°å·ç§¯æ ¸æ›¿æ¢å¤§å·ç§¯æ ¸ï¼Œæ˜¯å¦ä¼šå¸¦æ¥ä¿¡æ¯æŸå¤±(loss of expressiveness)? ä¸ä¼šï¼Œåªè¦å¤šæ¬¡å åŠ çš„å°å·ç§¯æ ¸å’Œå¼€å§‹çš„å¤§å·ç§¯æ ¸å…·æœ‰ç›¸åŒçš„receptive fieldã€‚2.å¦‚æžœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯¹è®¡ç®—å¼€é”€ä¸­çš„çº¿æ€§éƒ¨åˆ†è¿›è¡Œå› å¼åˆ†è§£ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆä¸ç›´æŽ¥åœ¨ç¬¬ä¸€æ¬¡ä¿æŒçº¿æ€§æ¿€æ´»ï¼ˆlinear activationï¼‰ï¼Ÿå› ä¸ºåœ¨å®žéªŒä¸­è¡¨æ˜Žï¼Œéžçº¿æ€§æ¿€æ´»æ€§èƒ½æ›´å¥½ã€‚ Label Smoothing Regularizationå› ä¸ºå¤§å¤šæ•°çš„æ•°æ®é›†éƒ½å­˜åœ¨é”™è¯¯çš„æ ‡ç­¾ï¼Œ ä½†æ˜¯minimize the cost function on the wrong labels can be harmfulã€‚å› æ­¤åœ¨Model Regularizationä¸­ï¼Œå¯ä»¥é€šè¿‡åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä¸»åŠ¨åŠ å…¥å™ªå£°ä½œä¸ºpenaltyï¼Œè¿™æ ·çš„æ¨¡åž‹å…·æœ‰noise Robustnessã€‚Label Smoothing Regularization(LSR)æ˜¯å…¶ä¸­çš„ä¸€ç§regularizationçš„æ–¹æ³•ã€‚ Here we propose a mechanism to regularize the classifier layer by estimating the marginalized effect of label-dropout duringtraining. {ä¸¾ä¸€ä¸ªUniversity of Waterlooçš„WAVE LABçš„ ME 780ä¸­lecture 3ï¼šRegularization for deep modelsçš„ä¾‹å­æ¥å¸®åŠ©ç†è§£ï¼šground-truth: y1_label=[1,0,0,â€¦â€¦ï¼Œ0]prediction: ç»è¿‡softmax classifierå¾—åˆ°çš„softmax output: y1_out=[0.87,0.001,0.04â€¦â€¦,0.03]. } maximum likelihood learning with softmax classifier and hard targets may actually never converge, the softmax cannever predict a probability of exactly 0 or 1, so it will continue to learn larger and larger weights, making moreextreme predictions. å‡è®¾xä¸ºtraining exampleï¼Œ$p(k|x)$ä¸ºxå±žäºŽã€Œlabel kã€çš„æ¦‚çŽ‡ï¼Œ$q(k|x)$ä¸ºxå±žäºŽã€Œground-truth labelã€çš„æ¦‚çŽ‡ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œå¿½ç•¥äº†på’Œqåœ¨example xä¸Šçš„ç›¸å…³æ€§ã€‚ ç›®æ ‡å‡½æ•°ï¼šã€Œæœ€å°åŒ–äº¤å‰ç†µã€ã€‚å› ä¸ºäº¤å‰ç†µè¡¡é‡çš„æ˜¯ä¸¤ä¸ªåˆ†å¸ƒï¼ˆpå’Œqï¼‰çš„ç›¸ä¼¼æ€§ï¼Œæœ€å°åŒ–ç›®æ ‡å‡½æ•°æ˜¯ä¸ºäº†è®©é¢„æµ‹çš„labelæ¦‚çŽ‡åˆ†å¸ƒ$p(k|x)$ï¼ˆå³ä¾‹å¦‚ä¸Šé¢çš„softmaxçš„è¾“å‡ºï¼‰å’Œground-truth labelçš„æ¦‚çŽ‡åˆ†å¸ƒ$q(k|x)$å°½å¯èƒ½çš„æŽ¥è¿‘ã€‚ã€Œæœ€å°åŒ–äº¤å‰ç†µã€ä¹Ÿç­‰ä»·ä¸ºã€Œæœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ã€ã€‚ä½†æ˜¯æˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªç›®æ ‡å‡½æ•°è¿›è¡Œäº†æ”¹è¿›ã€‚å› ä¸ºåœ¨å•ç±»æƒ…å†µä¸‹ï¼Œå•ä¸€çš„äº¤å‰ç†µå¯¼è‡´æ ·æœ¬å±žäºŽæŸä¸ªç±»åˆ«çš„æ¦‚çŽ‡éžå¸¸å¤§ï¼Œæ¨¡åž‹å¤ªè¿‡ä¸Žè‡ªä¿¡è‡ªå·±çš„åˆ¤æ–­ã€‚è¿™æ ·ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆï¼Œæ­¤å¤–è¿˜ä¼šé™ä½Žæ¨¡åž‹çš„é€‚åº”èƒ½åŠ›ã€‚ä¸ºäº†é¿å…æ¨¡åž‹è¿‡äºŽè‡ªä¿¡ï¼Œå¼•å…¥äº†ä¸€ä¸ªç‹¬ç«‹äºŽæ ·æœ¬åˆ†å¸ƒçš„å˜é‡u(k)ï¼Œè¿™ç›¸å½“äºŽåœ¨ground-truth distributionä¸­åŠ å…¥äº†å™ªå£°ï¼Œç»„æˆä¸€ä¸ªæ–°çš„åˆ†å¸ƒã€‚åœ¨å®žéªŒä¸­ï¼Œä½¿ç”¨çš„æ˜¯å‡åŒ€åˆ†å¸ƒ(uniform distribution)ä»£æ›¿äº†u(k) we propose a mechanism for encouraging the model to be less confident. While this may not be desired if the goal is to maximize the log-likelihood of training labels, it does regularize the model and makes it more adaptable â€¦â€¦ we refer to thischange in ground-truth label distribution as label-smoothing regularization, or LSR. Resnetintroductionä¸€èˆ¬æ¥è¯´ï¼Œæ¨¡åž‹çš„æ·±åº¦åŠ æ·±ï¼Œå­¦ä¹ èƒ½åŠ›å¢žå¼ºï¼Œä½†æ˜¯ä¸èƒ½ç®€å•çš„å¢žåŠ ç½‘ç»œçš„æ·±åº¦ï¼Œå¦åˆ™ä¼šå‡ºçŽ°éšç€ç½‘ç»œæ·±åº¦å¢žåŠ ï¼Œtraining errorå’Œtest errorå˜é«˜çš„çŽ°è±¡ã€‚è¿™ä¹Ÿè¯´æ˜Žç½‘ç»œç»“æž„å˜å¤æ‚æ—¶ï¼Œoptimizationå˜å¾—æ›´åŠ å›°éš¾ã€‚Kaiming Heæå‡ºäº†æ·±åº¦æ®‹å·®å­¦ä¹ ï¼ˆdeep residual learning frameworkï¼‰,é€šè¿‡ç½‘ç»œç»“æž„çš„åˆ›æ–°æ¥æœ‰æ•ˆçš„è§£å†³äº†ä¸Šè¿°çš„æ¢¯åº¦å¼¥æ•£çŽ°è±¡(degradation)ã€‚ ç½‘ç»œç»“æž„ ä»Žä»¥ä¸‹ä¸¤ç‚¹æ¥åˆ†æžç½‘ç»œç»“æž„çš„åˆ›æ–° shortcut connectionæ®‹å·®çš„ç½‘ç»œç»“æž„æ˜¯å‰å‘ç¥žç»ç½‘ç»œ+shortcutã€‚ä»Žä¸Šå›¾å¯ä»¥çœ‹å‡ºåœ¨å·²æœ‰çš„ç½‘ç»œç»“æž„ä¸­å¢žåŠ äº†ä¸€ä¸ªbranchï¼Œèµ·åˆ°çš„æ˜¯æ’ç­‰æ˜ å°„ï¼ˆidentity mappingï¼‰çš„ä½œç”¨ï¼Œè¿™æ ·ä¿è¯äº†ä¸€ä¸ªæ·±åº¦æ¨¡åž‹çš„training erroræœ€èµ·ç ä¿è¯shallow counterpartæ¨¡åž‹çš„training erroræ˜¯ä¸€è‡´çš„ï¼Œé”™è¯¯çŽ‡ä¸ä¼šé«˜äºŽæµ…å±‚ã€‚æ­¤å¤–ï¼Œè¿™ç§åšæ³•æ—¢ä¸ä¼šå¢žåŠ é¢å¤–çš„å‚æ•°ä¹Ÿä¸ä¼šå¢žåŠ é¢å¤–çš„è®¡ç®—é‡ã€‚ residual representationsä¸¤ç§å‡½æ•°çš„è¡¨è¾¾æ•ˆæžœæ˜¯ç›¸åŒçš„ï¼Œä½†æ˜¯ä¼˜åŒ–çš„éš¾åº¦æ˜¯ä¸åŒçš„ã€‚å¯¹æ®‹å·®è¿›è¡Œæ‹Ÿåˆæ˜¾ç„¶è¦æ›´åŠ å®¹æ˜“ã€‚æ®‹å·®å‡½æ•° $F(x):=H(x)-x$ã€‚å¼•å…¥æ®‹å·®åŽçš„æ˜ å°„å¯¹è¾“å‡ºçš„å˜åŒ–æ›´åŠ æ•æ„Ÿï¼Œå¦‚H(5)=5.1,F(5)=0.1, è¾“å‡ºä»Ž5.1å˜åŒ–åˆ°5.2ï¼Œå¢žåŠ çš„å¹…åº¦ä¸º2%ï¼Œä½†æ˜¯æ®‹å·®æ˜¯ä»Ž0.1å˜åŒ–åˆ°0.2ï¼Œå¢žåŠ å¹…åº¦ä¸º100%ã€‚æ®‹å·®çš„æ€æƒ³å°±æ˜¯åŽ»é™¤ç›¸åŒçš„ä¸»ä½“éƒ¨åˆ†ï¼Œçªå‡ºå¾®å°çš„å˜åŒ–ã€‚ è®¡ç®—å…¬å¼$${y}=F({x},{W_i})+W_s{x}$$å…¶ä¸­$F({x},{W_i})$å’Œ$x$æ˜¯éœ€è¦å­¦ä¹ çš„æ®‹å·®æ˜ å°„ï¼Œåœ¨è®¡ç®—çš„æ—¶å€™éœ€è¦ä¿è¯ç»´æ•°ä¸€è‡´ï¼Œè€ƒè™‘åˆ°åœ¨ä¸¤ä¸ªfeature map ä¸­è¿›è¡Œé€å…ƒç´ ç›¸åŠ ï¼ˆelement-wise addition)ã€‚å½“ç»´æ•°ä¸ä¸€è‡´çš„æ—¶å€™ï¼Œé€šè¿‡å¼•å…¥çº¿æ€§æ˜ å°„W_sæ¥åŒ¹é…ç»´åº¦ æœ€ç»ˆå–å¾—çš„æ•ˆæžœæ˜¯ï¼š these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. Inception-Resnetå› ä¸ºResidual connectionsåœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œæ—¶ï¼Œååˆ†æœ‰ä¼˜åŠ¿ï¼Œå†åŠ ä¸Šinceptionç½‘ç»œçš„æ·±åº¦ä¹Ÿæ¯”è¾ƒæ·±ï¼Œæ‰€ä»¥ä½œè€…å°è¯•å°†ä¸¤ç§æ–¹æ³•ç»“åˆèµ·æ¥ã€‚æ›´ç¡®åˆ‡çš„è¯´æ˜¯ï¼Œå°†Inceptionä¸­çš„filter concatenationä¸­çš„ä¸€éƒ¨åˆ†æ›¿æ¢ä¸ºresidual connectionsçš„ç»“æž„ã€‚ç»“åˆäº†residual connectionçš„inceptionæ¨¡å—å¦‚ä¸‹æ‰€ç¤ºï¼š ä½†æ˜¯å¼•å…¥residual connectionåŽï¼Œç½‘ç»œå¤ªæ·±ï¼Œç¨³å®šæ€§ä¸å¥½ï¼Œå› æ­¤å†æ¬¡åšäº†ä¿®æ”¹ã€‚å›¾ä¸­inceptionæ¡†å¯ä»¥ç”¨ä»»æ„å…¶ä»–subnetworkæ›¿ä»£ï¼Œä½†æ˜¯è¿™æ¬¡ä¿®æ”¹æ˜¯åœ¨è¾“å‡ºåŽå¼•å…¥äº†ç¼©æ”¾ç³»æ•°(scale),å†ç›¸åŠ å’Œæ¿€æ´»ã€‚æ–‡ç« æå‡ºäº†ä¸¤ä¸ªç‰ˆæœ¬ï¼šInception-ResNet v1å’ŒInception-ResNet v2ï¼Œç›¸æ¯”åŽŸæ¥ï¼ŒåŠ å¿«è®­ç»ƒçš„æ”¶æ•›é€Ÿåº¦ã€‚åœ¨å›¾åƒè¯†åˆ«ï¼Œè§†é¢‘æ£€æµ‹ç­‰é¢†åŸŸéƒ½ä½œä¸ºäº†base-networkã€‚ In the experimental section we demonstrate that it is not very difficult to train competitive very deep networks without utilizing residual connections. However the use of residual connections seems to improve the training speed greatly, which is alone a great argument for their use.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>å…¥é—¨</tag>
      </tags>
  </entry>
</search>
